# Project Revision: Enhancing Forecasting Robustness through Improved Signal Processing and Density-Based Filtering

<img width="1122" height="626" alt="image" src="https://github.com/user-attachments/assets/c4a0cd71-be24-46d7-a015-033df3bf5fcc" />


## ğŸ“ˆ Executive Summary

This technical revision delineates a robust engineering framework designed to mitigate the high **Stochasticity** (rastlantÄ±sallÄ±k) inherent in the Online Retail II dataset. By transitioning from a standard aggregate approach to a **Segment-Wise-Customer-Wise (SWCW)** methodology, we aim to isolate the **"Latent Behavioral Signal"** from seasonal **"Market Static."**

### Key Business Value Drivers:

* ğŸ¯ **Precision Targeting:** Moving beyond volume-based metrics to **Habitual Density** ensures that marketing and supply chain resources are allocated to predictable, high-value cohorts.
* ğŸ›¡ï¸ **Operational Integrity:** Advanced signal sanitation (**Winsorization** and **Linear Interpolation**) prevents the artificial inflation of financial projections caused by extreme outliers.
* ğŸ“Š **Predictive Reliability:** By resolving the **Scale-Mismatch** in noisy data, we achieve a lower **sMAPE**, directly translating to optimized inventory turnover.

---

## ğŸ—ï¸ Technical Architecture: The End-to-End Pipeline

### Phase 1: Data Ingestion & Infrastructure Initialization (Obtain) ğŸ“¥
* **Environment Orchestration:** Configuration of high-performance compute resources (GPU/CPU) and deployment of specialized dependencies (e.g., `pmdarima`, `statsmodels`).
* **Library Synchronization:** Loading core computational frameworks for signal processing (`scipy.signal`), statistical modeling (`statsmodels`), and machine learning (`sklearn`).
* **Data Acquisition & Preliminary Inspection:** Executing initial ingestion and verifying data schema integrity via descriptive statistical summaries (`.describe()`) and structural metadata analysis (`.info()`).

![Data Pipeline Overview]

### Phase 2: Advanced Data Sanitation & Feature Rectification (Scrub) ğŸ§¹
* **Data Sanitization (Advanced):**
    * **Deduplication:** Removal of redundant entries based on Invoice, StockCode, and Customer ID to prevent autocorrelation bias.
    * **Net Revenue Logic:** Implementation of a **"Return Strategy"** where $TotalAmount$ is calculated as $Quantity \times Price$, ensuring that credit notes and returns are treated as additive signal corrections rather than isolated noise.
    * **Outlier Mitigation:** Application of **Winsorization** (95th percentile limit) to neutralize the influence of heavy-tailed distributions and anomalous corporate bulk purchases.
* **Post-Scrub Distribution Analysis:** Statistical validation of the sanitized features. Visualizing the **"Spending Distribution"** and **"Return Ratio"** to confirm the normalization of the dataset and readiness for modeling.

### Phase 3: Stochastic Signal Filtering (Engineering - Part 1) ğŸ”
* **Habitual Density Thresholding:** Filtering for customers with a transaction density $\ge 70\%$.
* **Engineering Logic:** This step is prioritized to ensure that subsequent statistical tests are executed only on "model-able" signals, significantly increasing the **Signal-to-Noise Ratio (SNR)**.

### Phase 4: Temporal Exploratory Data Analysis (Explore) ğŸ•°ï¸
* **Deep Temporal EDA (T-EDA):**
    * **Stationarity Assessment:** Execution of the **Augmented Dickey-Fuller (ADF)** Test to determine the integration order ($d$ parameter).
    * **Order Selection:** Analysis of **ACF/PACF** (Autocorrelation and Partial Autocorrelation) plots to identify the $p$ (Auto-regressive) and $q$ (Moving Average) components.
    * **Time-Series Decomposition:** Isolating Trend, Seasonality ($m, S$), and Residuals to inform the hyperparameter tuning of the seasonal ARIMA model.

![Time Series Decomposition Components]

### Phase 5: Hybrid Behavioral Clustering & Multi-View Alignment (Engineering - Part 2) ğŸ§©
* **The "RFM Bridge" (Hybrid Feature Engineering):**
    * Calculation of **RFM (Recency, Frequency, Monetary)** metrics to provide a business-logic layer.
    * Computation of the **Complexity-Invariant Distance (CID)** Matrix to capture temporal shape similarity.
    * **Feature Scaling:** Unification of diverse metric scales through `MinMaxScaler` or `StandardScaler` to ensure dimensional parity.
* **Hierarchical Clustering Depth:**
    * Deployment of the **Elbow Method** and **Silhouette Analysis** to determine the optimal $k$-clusters.
    * Application of **K-Means++** or **Wardâ€™s Hierarchical Clustering** to define customer behavioral segments.

### Phase 6: SWCW Predictive Modeling & Validation (Model & Evaluate) ğŸ¤–
* **Segment-Wise-Customer-Wise (SWCW) Forecasting:**
    * Iterative execution of `auto_arima` loops for every individual customer within each segment, allowing for local hyperparameter optimization.
* **Multi-Metric Evaluation:** Benchmarking performance using **sMAPE**, **MAE**, and **RMSE** at the segment level.
* **Root Cause Error Analysis:** Identifying segment-specific failures (e.g., why Cluster X deviates from the ARIMA linearity) to refine future iterations.

### Phase 7: Signal Reconstruction & Visual Synthesis (Interpret) ğŸ“ˆ
* **Refined Signal Smoothing:** Implementation of the **Savitzky-Golay Filter** to reconstruct the "Actual" trend line by removing high-frequency retail noise without introducing phase shift.
* **Interpretive Visualization:** Final presentation of **"Actual vs. Forecast"** plots in a publication-standard format, highlighting the predictive delta across diverse behavioral segments.

---

## ğŸ”¬ Technical Update: Comparison of Improvements

| Analysis Area | Problem Identified | Engineering Solution | Expected Outcome |
| :--- | :--- | :--- | :--- |
| **Data Imputation** | Zero-filling creating extreme gradients. | **Linear Interpolation** | Prevention of biased CID clustering. |
| **Stochasticity** | High-frequency "spikes" in retail data. | **Savitzky-Golay Smoothing** | Stabilization of the input signal for ARIMA. |
| **Customer Selection** | Simple activity thresholds were too loose. | **Habitual Density Filtering** | Elimination of "Impulse" noise from habit-based models. |
| **Metric Precision** | Scale-mismatch in noisy segments. | **Segment-Specific ARIMA** | Lowered sMAPE and higher forecasting precision. |

![Forecast Comparison Plot]




----
## TURKISH VERSION:

# Proje Revizyonu: Sinyal Ä°ÅŸleme ve YoÄŸunluk Temelli Filtreleme Yoluyla Tahmin SaÄŸlamlÄ±ÄŸÄ±nÄ±n ArtÄ±rÄ±lmasÄ± 

## ğŸ“ˆ YÃ¶netici Ã–zeti 

Bu teknik revizyon, **Online Retail II** veri setinde doÄŸal olarak bulunan yÃ¼ksek **RastlantÄ±sallÄ±ÄŸÄ± (Stochasticity)** azaltmak iÃ§in tasarlanmÄ±ÅŸ saÄŸlam bir mÃ¼hendislik Ã§erÃ§evesini tanÄ±mlar. Standart bir toplu yaklaÅŸÄ±mdan **Segment BazlÄ±-MÃ¼ÅŸteri BazlÄ± (Segment-Wise-Customer-Wise - SWCW)** metodolojisine geÃ§iÅŸ yaparak, mevsimsel "Pazar StatikliÄŸinden" **"Ã–rtÃ¼k DavranÄ±ÅŸsal Sinyali" (Latent Behavioral Signal)** izole etmeyi hedefliyoruz.

### Temel Ä°ÅŸ DeÄŸeri Ä°tici GÃ¼Ã§leri
* **Hassas Hedefleme (Precision Targeting):** Hacim odaklÄ± metriklerin Ã¶tesine geÃ§erek **AlÄ±ÅŸkanlÄ±k YoÄŸunluÄŸuna (Habitual Density)** odaklanmak, pazarlama ve tedarik zinciri kaynaklarÄ±nÄ±n Ã¶ngÃ¶rÃ¼lebilir ve yÃ¼ksek deÄŸerli kohortlara ayrÄ±lmasÄ±nÄ± saÄŸlar.
* **Operasyonel BÃ¼tÃ¼nlÃ¼k (Operational Integrity):** GeliÅŸmiÅŸ sinyal sanitasyonu (**Winsorizasyon (Winsorization)** ve **Lineer Ä°nterpolasyon (Linear Interpolation)**), uÃ§ deÄŸerlerin (outliers) neden olduÄŸu yapay finansal projeksiyon ÅŸiÅŸkinliklerini Ã¶nler.
* **Tahmin GÃ¼venilirliÄŸi (Predictive Reliability):** GÃ¼rÃ¼ltÃ¼lÃ¼ verilerdeki **Ã–lÃ§ek UyumsuzluÄŸunu (Scale-Mismatch)** Ã§Ã¶zerek, doÄŸrudan optimize edilmiÅŸ envanter devir hÄ±zÄ±na dÃ¶nÃ¼ÅŸen daha dÃ¼ÅŸÃ¼k bir **SMAPE** deÄŸerine ulaÅŸÄ±rÄ±z.

---

## ğŸ—ï¸ Teknik Mimari: UÃ§tan Uca Boru HattÄ± 

### AÅŸama 1: Veri AlÄ±mÄ± ve AltyapÄ± BaÅŸlatma 
* **Ortam Orkestrasyonu (Environment Orchestration):** YÃ¼ksek performanslÄ± hesaplama kaynaklarÄ±nÄ±n (GPU/CPU) konfigÃ¼rasyonu ve Ã¶zel baÄŸÄ±mlÄ±lÄ±klarÄ±n (**pmdarima**, **statsmodels**) konuÅŸlandÄ±rÄ±lmasÄ±.
* **KÃ¼tÃ¼phane Senkronizasyonu (Library Synchronization):** Sinyal iÅŸleme (**scipy.signal**), istatistiksel modelleme (**statsmodels**) ve makine Ã¶ÄŸrenmesi (**sklearn**) iÃ§in temel hesaplama Ã§erÃ§evelerinin yÃ¼klenmesi.
* **Veri Edinimi ve Ã–n Ä°nceleme (Data Acquisition & Preliminary Inspection):** Ä°lk veri alÄ±mÄ±nÄ±n gerÃ§ekleÅŸtirilmesi ve aÃ§Ä±klayÄ±cÄ± istatistiksel Ã¶zetler (**`.describe()`**) ve yapÄ±sal meta veri analizi (**`.info()`**) yoluyla veri ÅŸemasÄ± bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼n doÄŸrulanmasÄ±.

### AÅŸama 2: GeliÅŸmiÅŸ Veri Temizleme ve Ã–zellik DÃ¼zeltme 
* **Veri Sanitasyonu (Data Sanitization):**
    * **TekilleÅŸtirme (Deduplication):** Otokorelasyon sapmasÄ±nÄ± (**Autocorrelation bias**) Ã¶nlemek iÃ§in Fatura, Stok Kodu ve MÃ¼ÅŸteri KimliÄŸine dayalÄ± yinelenen giriÅŸlerin kaldÄ±rÄ±lmasÄ±.
    * **Net Gelir MantÄ±ÄŸÄ± (Net Revenue Logic):** Toplam TutarÄ±n (**TotalAmount**) $Quantity \times Price$ olarak hesaplandÄ±ÄŸÄ± bir "Ä°ade Stratejisi" uygulanarak, kredi notlarÄ±nÄ±n ve iadelerin izole gÃ¼rÃ¼ltÃ¼ yerine eklemeli sinyal dÃ¼zeltmeleri olarak ele alÄ±nmasÄ±.
* **AykÄ±rÄ± DeÄŸer Azaltma (Outlier Mitigation):** AÄŸÄ±r kuyruklu daÄŸÄ±lÄ±mlarÄ±n (**Heavy-tailed distributions**) ve anormal kurumsal toplu alÄ±mlarÄ±n etkisini nÃ¶tralize etmek iÃ§in **Winsorizasyon (Winsorization)** (%95 persentil sÄ±nÄ±rÄ±) uygulamasÄ±.
* **Temizlik SonrasÄ± DaÄŸÄ±lÄ±m Analizi (Post-Scrub Distribution Analysis):** TemizlenmiÅŸ Ã¶zelliklerin istatistiksel doÄŸrulamasÄ±. Veri setinin normalleÅŸmesini ve modellemeye hazÄ±r olduÄŸunu teyit etmek iÃ§in **"Harcama DaÄŸÄ±lÄ±mÄ±" (Spending Distribution)** ve **"Ä°ade OranÄ±" (Return Ratio)** gÃ¶rsellerinin oluÅŸturulmasÄ±.



### AÅŸama 3: Stokastik Sinyal Filtreleme ( Engineering Part 1)
* **AlÄ±ÅŸkanlÄ±k YoÄŸunluÄŸu EÅŸikleme (Habitual Density Thresholding):** Ä°ÅŸlem yoÄŸunluÄŸu $\ge \%70$ olan mÃ¼ÅŸteriler iÃ§in filtreleme.
* **MÃ¼hendislik MantÄ±ÄŸÄ± (Engineering Logic):** Bu adÄ±m, sonraki istatistiksel testlerin yalnÄ±zca "modellenebilir" sinyaller Ã¼zerinde yÃ¼rÃ¼tÃ¼lmesini saÄŸlamak ve **Sinyal-GÃ¼rÃ¼ltÃ¼ OranÄ±nÄ± (Signal-to-Noise Ratio - SNR)** Ã¶nemli Ã¶lÃ§Ã¼de artÄ±rmak iÃ§in Ã¶nceliklendirilmiÅŸtir.

### AÅŸama 4: Zamansal KeÅŸifÃ§i Veri Analizi 
* **Derin Zamansal EDA :**
    * **DuraÄŸanlÄ±k DeÄŸerlendirmesi (Stationarity Assessment):** Entegrasyon sÄ±rasÄ±nÄ± (**$d$ parametresi**) belirlemek iÃ§in **GeniÅŸletilmiÅŸ Dickey-Fuller (ADF) Testi** uygulamasÄ±.
    * **Derece SeÃ§imi (Order Selection):** **$p$ (Oto-regresif)** ve **$q$ (Hareketli Ortalama)** bileÅŸenlerini tanÄ±mlamak iÃ§in **ACF/PACF** grafiklerinin analizi.
    * **Zaman Serisi AyrÄ±ÅŸtÄ±rma (Time-Series Decomposition):** Mevsimsel ARIMA modelinin hiperparametre ayarlarÄ±nÄ± bilgilendirmek iÃ§in **Trend, Mevsimsellik ($m, S$) ve ArtÄ±klarÄ± (Residuals)** izole etme.

### AÅŸama 5: Hibrit DavranÄ±ÅŸsal KÃ¼meleme ve Ã‡ok GÃ¶rÃ¼nÃ¼mlÃ¼ Hizalama ( Engineering Part 2)
* **"RFM KÃ¶prÃ¼sÃ¼" (The RFM Bridge):**
    * Ä°ÅŸ mantÄ±ÄŸÄ± katmanÄ± saÄŸlamak iÃ§in **RFM (Recency, Frequency, Monetary)** metriklerinin hesaplanmasÄ±.
    * Zamansal ÅŸekil benzerliÄŸini yakalamak iÃ§in **KarmaÅŸÄ±klÄ±k-DeÄŸiÅŸmez Mesafe (Complexity-Invariant Distance - CID)** matrisinin hesaplanmasÄ±.
    * **Ã–zellik Ã–lÃ§eklendirme (Feature Scaling):** Boyutsal eÅŸitliÄŸi saÄŸlamak iÃ§in **MinMaxScaler** veya **StandardScaler** yoluyla farklÄ± metrik Ã¶lÃ§eklerinin birleÅŸtirilmesi.
* **HiyerarÅŸik KÃ¼meleme DerinliÄŸi (Hierarchical Clustering Depth):**
    * Optimal $k$-kÃ¼me sayÄ±sÄ±nÄ± belirlemek iÃ§in **Dirsek YÃ¶ntemi (Elbow Method)** ve **SilÃ¼et Analizi (Silhouette Analysis)** kullanÄ±mÄ±.
    * MÃ¼ÅŸteri davranÄ±ÅŸ segmentlerini tanÄ±mlamak iÃ§in **K-Means++** veya **Ward HiyerarÅŸik KÃ¼meleme** uygulamasÄ±.

### AÅŸama 6: SWCW Tahminleme ve DoÄŸrulama 
* **Segment BazlÄ±-MÃ¼ÅŸteri BazlÄ± Tahminleme (SWCW Forecasting):**
    * Her segmentteki her bir mÃ¼ÅŸteri iÃ§in yerel hiperparametre optimizasyonuna izin veren **auto_arima** dÃ¶ngÃ¼lerinin iteratif yÃ¼rÃ¼tÃ¼lmesi.
* **Ã‡ok Metrikli DeÄŸerlendirme (Multi-Metric Evaluation):** Segment dÃ¼zeyinde **SMAPE, MAE ve RMSE** kullanarak performans kÄ±yaslamasÄ± (**Benchmarking**).
* **KÃ¶k Neden Hata Analizi (Root Cause Error Analysis):** Gelecekteki iterasyonlarÄ± iyileÅŸtirmek iÃ§in segmente Ã¶zgÃ¼ baÅŸarÄ±sÄ±zlÄ±klarÄ±n (Ã¶rneÄŸin, KÃ¼me X'in neden ARIMA lineerliÄŸinden saptÄ±ÄŸÄ±) belirlenmesi.

### AÅŸama 7: Sinyal Yeniden YapÄ±landÄ±rma ve GÃ¶rsel Sentez 
* **Rafine Sinyal YumuÅŸatma (Refined Signal Smoothing):** Faz kaymasÄ± yaratmadan yÃ¼ksek frekanslÄ± perakende gÃ¼rÃ¼ltÃ¼sÃ¼nÃ¼ gidererek "GerÃ§ek" trend Ã§izgisini yeniden oluÅŸturmak iÃ§in **Savitzky-Golay Filtresi** uygulamasÄ±.
* **YorumlayÄ±cÄ± GÃ¶rselleÅŸtirme (Interpretive Visualization):** Ã‡eÅŸitli davranÄ±ÅŸ segmentlerinde tahmin sapmasÄ±nÄ± vurgulayan, yayÄ±n standartlarÄ±nda **"GerÃ§ek vs. Tahmin"** grafiklerinin sunumu.

---

## ğŸ“Š KarÅŸÄ±laÅŸtÄ±rmalÄ± Analiz Tablosu 

| Analiz AlanÄ± | Problemler & BileÅŸenler | Teknik Detay & Ã–nem | Ã‡Ã¶zÃ¼m YÃ¶ntemleri | AraÃ§lar & Testler |
| :--- | :--- | :--- | :--- | :--- |
| **Veri Kalitesi** | GÃ¼rÃ¼ltÃ¼ ve AykÄ±rÄ± DeÄŸerler | Tahmin sapmasÄ±nÄ± (bias) azaltÄ±r | Winsorization, Net Revenue Logic | Scipy, Pandas |
| **Sinyal GÃ¼cÃ¼** | DÃ¼ÅŸÃ¼k SNR (Signal-to-Noise) | Modellenebilir veriyi ayÄ±rÄ±r | Habitual Density Thresholding | Custom Filters, ADF Test |
| **Segmentasyon** | DavranÄ±ÅŸsal Homojenlik | Tahmin doÄŸruluÄŸunu artÄ±rÄ±r | RFM & CID Matrix Hybrid | K-Means++, Silhouette |
| **Modelleme** | Ã–lÃ§ek UyumsuzluÄŸu | Yerel paternleri yakalar | SWCW (Segment-Wise) | Auto-ARIMA, Statsmodels |

---

## ğŸ’¡ Ä°ÅŸ Ä°Ã§gÃ¶rÃ¼leri

1.  **"So What?" (Peki ya Sonra?):** RastlantÄ±sallÄ±ÄŸÄ± %70 yoÄŸunluk eÅŸiÄŸiyle filtreleyerek, pazarlama bÃ¼tÃ§esinin boÅŸa harcandÄ±ÄŸÄ± "gÃ¼rÃ¼ltÃ¼lÃ¼" mÃ¼ÅŸteri grubundan kaÃ§Ä±nÄ±lmÄ±ÅŸtÄ±r. Bu, **MÃ¼ÅŸteri Edinme Maliyeti (CAC)** verimliliÄŸini doÄŸrudan artÄ±rÄ±r.
2.  **Stratejik Stok YÃ¶netimi:** Savitzky-Golay filtresi ile temizlenen trendler, ani talep sÄ±Ã§ramalarÄ±na (anomaliler) karÅŸÄ± aÅŸÄ±rÄ± stok (overstocking) yapÄ±lmasÄ±nÄ± Ã¶nleyerek depo maliyetlerini dÃ¼ÅŸÃ¼rÃ¼r.
3.  **KiÅŸiselleÅŸtirilmiÅŸ Tahmin:** Her segmentin kendi ARIMA parametrelerine sahip olmasÄ±, "herkese uyan tek model" yaklaÅŸÄ±mÄ±nÄ±n getirdiÄŸi genel hata payÄ±nÄ± minimize eder.

---

## ğŸ“ Ekler (Appendix)

Bu projenin teknik detaylarÄ±, kullanÄ±lan matematiksel formÃ¼ller ve hiperparametre optimizasyon sÃ¼reÃ§leri kod bloklarÄ± iÃ§erisinde `technical-appendix.md` dosyasÄ±nda saklanmaktadÄ±r.
